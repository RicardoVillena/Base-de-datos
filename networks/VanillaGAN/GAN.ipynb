{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ubNyAhYB9pq"
      },
      "source": [
        "# Self Implementation of Vanilla GAN\n",
        "Paper: https://arxiv.org/pdf/1406.2661.pdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHJGH708oV6I",
        "outputId": "408f0d84-8390-4e45-83f3-1e1a23315d9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1AcX1JwCPlo"
      },
      "source": [
        "array2gif allows making gifs from numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysQfJECB7Z5_",
        "outputId": "411f8240-de15-430a-9d54-87280feed4b9"
      },
      "source": [
        "!pip install array2gif"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting array2gif\n",
            "  Downloading array2gif-1.0.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from array2gif) (2.0.2)\n",
            "Downloading array2gif-1.0.4-py3-none-any.whl (7.8 kB)\n",
            "Installing collected packages: array2gif\n",
            "Successfully installed array2gif-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E69kk8i2rfXs"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import torchvision\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_size = 100):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "        self.model       = nn.Sequential(nn.Linear(latent_size, 6*6),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(6*6, 12*12),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(12*12, 28*28),\n",
        "                                         nn.Tanh()\n",
        "                                         )\n",
        "    def __call__(self, latent):\n",
        "        return self.forward(latent)\n",
        "\n",
        "    def forward(self, latent):\n",
        "        gen = self.model(latent)\n",
        "        gen = gen.view((gen.size()[0],*(1,28,28)))\n",
        "        return gen\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(nn.Linear(28*28, 12*12),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Linear(12*12, 6*6),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Linear(6*6, 1),\n",
        "                              nn.Sigmoid()\n",
        "                              )\n",
        "    def __call__(self, img):\n",
        "        return self.forward(img)\n",
        "\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(img.size()[0], -1)\n",
        "        decision = self.model(flattened.cuda())\n",
        "        return decision\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsBoSiSyCcSx"
      },
      "source": [
        "Function to plot results every now and then just for being sure everything is fine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUb_SAoZrjME"
      },
      "source": [
        "def plot_epoch(images, n=36):\n",
        "    '''\n",
        "    Visualize a single epoch of images\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    images : numpy.ndarray\n",
        "             images of shape (b, c, x, y)\n",
        "    n      : int, default: 36\n",
        "             number of images to display. Must be a square number\n",
        "    '''\n",
        "\n",
        "    if not isinstance(images, np.ndarray):\n",
        "        images = images.detach().numpy()\n",
        "\n",
        "    rowcols = np.sqrt(n)\n",
        "    plt.figure(figsize=(rowcols, rowcols))\n",
        "    for index in range(n):\n",
        "        plt.subplot(rowcols, rowcols, index + 1)\n",
        "        plt.imshow(images[index, 0, :, :], cmap=\"binary\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSJKjRCArueq",
        "outputId": "c0844ff0-22c6-4d7c-989c-08000af9f346"
      },
      "source": [
        "from torch.optim import Adam\n",
        "from torchvision.datasets import MNIST\n",
        "from array2gif import write_gif\n",
        "\n",
        "LATENT_SIZE = 100\n",
        "EPOCH_SIZE  = 300\n",
        "ROW_NUM     = 6\n",
        "try:\n",
        "  data_path = os.path.join(os.path.abspath(os.environ[\"CONDA_PREFIX\"]),\n",
        "                          'datasets')\n",
        "except KeyError:\n",
        "    data_path = os.path.join(os.path.abspath(os.environ[\"HOME\"]),\n",
        "                         'datasets')\n",
        "# We make sure that the dataset is actually available\n",
        "try:\n",
        "    torchvision.datasets.MNIST(root=data_path,\n",
        "                               download=False)\n",
        "except RuntimeError or KeyError:\n",
        "    if not os.path.isdir(data_path):\n",
        "            os.makedirs(data_path)\n",
        "    torchvision.datasets.MNIST(root=data_path,\n",
        "                               download=True)\n",
        "\n",
        "\n",
        "dataset = torchvision.datasets.MNIST(root=data_path,download=True)\n",
        "dataset.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
        "                                                    torchvision.transforms.Normalize(mean = (0.5,),\n",
        "                                                                                     std = (0.5,))])\n",
        "\n",
        "\n",
        "# Data Loader\n",
        "batch_size = 128\n",
        "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True, drop_last=True)\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device is: \" + str(device))\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "discriminator = Discriminator().to(device)\n",
        "generator     = Generator().to(device)\n",
        "\n",
        "optim_d = Adam(discriminator.parameters(), lr = 0.0002)\n",
        "optim_g = Adam(generator.parameters(),     lr = 0.0002)\n",
        "\n",
        "gif_array = []*EPOCH_SIZE\n",
        "total_step = len(data_loader)\n",
        "for epoch in range(EPOCH_SIZE):\n",
        "    for step, (imgs, _) in enumerate(data_loader):\n",
        "\n",
        "        # Create Fake and Real Labels\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # ================================================================== #\n",
        "        #                      Train the discriminator                       #\n",
        "        # ================================================================== #\n",
        "        outputs     = discriminator(imgs)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "        real_score = outputs\n",
        "\n",
        "        # BCE on fake images\n",
        "        lat_space   = torch.randn(batch_size, LATENT_SIZE).to(device)\n",
        "        fake_images = generator(lat_space)\n",
        "        outputs     = discriminator(fake_images)\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "        fake_score  = outputs\n",
        "\n",
        "        # Backprop and optimize\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        optim_d.zero_grad()\n",
        "        optim_g.zero_grad()\n",
        "        d_loss.backward()\n",
        "        optim_d.step()\n",
        "\n",
        "        # ================================================================== #\n",
        "        #                        Train the generator                         #\n",
        "        # ================================================================== #\n",
        "\n",
        "        # Compute loss with fake images\n",
        "        lat_space = torch.randn(batch_size, LATENT_SIZE).to(device)\n",
        "        fake_images = generator(lat_space)\n",
        "        outputs = discriminator(fake_images)\n",
        "\n",
        "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "\n",
        "        # Backprop and optimize\n",
        "        optim_d.zero_grad()\n",
        "        optim_g.zero_grad()\n",
        "        g_loss.backward()\n",
        "        optim_g.step()\n",
        "\n",
        "        if (step+1) % 200 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'\n",
        "                    .format(epoch, EPOCH_SIZE,\n",
        "                            step+1, total_step,\n",
        "                            d_loss.item(),\n",
        "                            g_loss.item(),\n",
        "                            real_score.mean().item(),\n",
        "                            fake_score.mean().item()))\n",
        "    # plot_epoch(fake_images.cpu())\n",
        "    array_2_make_grid = ((fake_images.cpu()[0:ROW_NUM**2, :, :, :] + 1) * (1/2) * 255).type(torch.uint8)\n",
        "    gif_array.append(torchvision.utils.make_grid(array_2_make_grid, nrow = ROW_NUM).numpy())\n",
        "write_gif(gif_array, filename = 'vanilla_10_fps.gif', fps = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.3MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 499kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.69MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 14.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device is: cuda\n",
            "Epoch [0/300], Step [200/468], d_loss: 0.4350, g_loss: 1.4595, D(x): 0.91, D(G(z)): 0.28\n",
            "Epoch [0/300], Step [400/468], d_loss: 1.0629, g_loss: 0.7765, D(x): 0.77, D(G(z)): 0.53\n",
            "Epoch [1/300], Step [200/468], d_loss: 0.1727, g_loss: 2.5631, D(x): 0.95, D(G(z)): 0.11\n",
            "Epoch [1/300], Step [400/468], d_loss: 1.1835, g_loss: 1.6550, D(x): 0.66, D(G(z)): 0.44\n",
            "Epoch [2/300], Step [200/468], d_loss: 0.1483, g_loss: 3.3558, D(x): 0.93, D(G(z)): 0.06\n",
            "Epoch [2/300], Step [400/468], d_loss: 0.8825, g_loss: 1.3820, D(x): 0.76, D(G(z)): 0.37\n",
            "Epoch [3/300], Step [200/468], d_loss: 1.1328, g_loss: 1.5236, D(x): 0.58, D(G(z)): 0.29\n",
            "Epoch [3/300], Step [400/468], d_loss: 0.0958, g_loss: 3.2778, D(x): 0.96, D(G(z)): 0.05\n",
            "Epoch [4/300], Step [200/468], d_loss: 0.8100, g_loss: 1.5148, D(x): 0.72, D(G(z)): 0.29\n",
            "Epoch [4/300], Step [400/468], d_loss: 1.5082, g_loss: 1.8873, D(x): 0.58, D(G(z)): 0.38\n",
            "Epoch [5/300], Step [200/468], d_loss: 0.5920, g_loss: 2.2620, D(x): 0.79, D(G(z)): 0.22\n",
            "Epoch [5/300], Step [400/468], d_loss: 0.1010, g_loss: 3.2006, D(x): 0.97, D(G(z)): 0.07\n",
            "Epoch [6/300], Step [200/468], d_loss: 0.3331, g_loss: 2.5375, D(x): 0.84, D(G(z)): 0.11\n",
            "Epoch [6/300], Step [400/468], d_loss: 1.7293, g_loss: 1.1340, D(x): 0.50, D(G(z)): 0.44\n",
            "Epoch [7/300], Step [200/468], d_loss: 0.7949, g_loss: 1.0896, D(x): 0.74, D(G(z)): 0.31\n",
            "Epoch [7/300], Step [400/468], d_loss: 0.2564, g_loss: 2.3381, D(x): 0.90, D(G(z)): 0.12\n",
            "Epoch [8/300], Step [200/468], d_loss: 1.3547, g_loss: 1.2760, D(x): 0.63, D(G(z)): 0.46\n",
            "Epoch [8/300], Step [400/468], d_loss: 0.8982, g_loss: 1.7322, D(x): 0.70, D(G(z)): 0.32\n",
            "Epoch [9/300], Step [200/468], d_loss: 1.6756, g_loss: 1.1425, D(x): 0.56, D(G(z)): 0.48\n",
            "Epoch [9/300], Step [400/468], d_loss: 0.5969, g_loss: 2.5289, D(x): 0.81, D(G(z)): 0.24\n",
            "Epoch [10/300], Step [200/468], d_loss: 0.8502, g_loss: 1.1229, D(x): 0.70, D(G(z)): 0.33\n",
            "Epoch [10/300], Step [400/468], d_loss: 1.1747, g_loss: 1.0523, D(x): 0.60, D(G(z)): 0.38\n",
            "Epoch [11/300], Step [200/468], d_loss: 0.9018, g_loss: 1.4777, D(x): 0.67, D(G(z)): 0.29\n",
            "Epoch [11/300], Step [400/468], d_loss: 1.2636, g_loss: 1.3089, D(x): 0.65, D(G(z)): 0.46\n",
            "Epoch [12/300], Step [200/468], d_loss: 2.6875, g_loss: 1.4964, D(x): 0.50, D(G(z)): 0.55\n",
            "Epoch [12/300], Step [400/468], d_loss: 1.8664, g_loss: 1.7983, D(x): 0.58, D(G(z)): 0.46\n",
            "Epoch [13/300], Step [200/468], d_loss: 0.8269, g_loss: 1.4282, D(x): 0.71, D(G(z)): 0.28\n",
            "Epoch [13/300], Step [400/468], d_loss: 1.5787, g_loss: 1.0721, D(x): 0.51, D(G(z)): 0.37\n",
            "Epoch [14/300], Step [200/468], d_loss: 0.8096, g_loss: 1.3586, D(x): 0.68, D(G(z)): 0.25\n",
            "Epoch [14/300], Step [400/468], d_loss: 1.3640, g_loss: 1.0512, D(x): 0.58, D(G(z)): 0.41\n",
            "Epoch [15/300], Step [200/468], d_loss: 2.3854, g_loss: 0.8428, D(x): 0.44, D(G(z)): 0.57\n",
            "Epoch [15/300], Step [400/468], d_loss: 1.3179, g_loss: 1.1724, D(x): 0.61, D(G(z)): 0.40\n",
            "Epoch [16/300], Step [200/468], d_loss: 0.7683, g_loss: 1.5642, D(x): 0.75, D(G(z)): 0.31\n",
            "Epoch [16/300], Step [400/468], d_loss: 1.3778, g_loss: 0.9712, D(x): 0.55, D(G(z)): 0.42\n",
            "Epoch [17/300], Step [200/468], d_loss: 1.8566, g_loss: 0.8876, D(x): 0.46, D(G(z)): 0.49\n",
            "Epoch [17/300], Step [400/468], d_loss: 1.6594, g_loss: 1.2415, D(x): 0.64, D(G(z)): 0.57\n",
            "Epoch [18/300], Step [200/468], d_loss: 0.3812, g_loss: 2.8166, D(x): 0.86, D(G(z)): 0.13\n",
            "Epoch [18/300], Step [400/468], d_loss: 1.2190, g_loss: 1.4621, D(x): 0.65, D(G(z)): 0.45\n",
            "Epoch [19/300], Step [200/468], d_loss: 1.2878, g_loss: 1.6457, D(x): 0.60, D(G(z)): 0.32\n",
            "Epoch [19/300], Step [400/468], d_loss: 0.9376, g_loss: 1.6196, D(x): 0.61, D(G(z)): 0.26\n",
            "Epoch [20/300], Step [200/468], d_loss: 1.1584, g_loss: 1.0459, D(x): 0.59, D(G(z)): 0.39\n",
            "Epoch [20/300], Step [400/468], d_loss: 1.4757, g_loss: 0.8141, D(x): 0.52, D(G(z)): 0.44\n",
            "Epoch [21/300], Step [200/468], d_loss: 1.7051, g_loss: 0.9510, D(x): 0.44, D(G(z)): 0.39\n",
            "Epoch [21/300], Step [400/468], d_loss: 1.2937, g_loss: 0.8245, D(x): 0.61, D(G(z)): 0.48\n",
            "Epoch [22/300], Step [200/468], d_loss: 0.7292, g_loss: 1.4198, D(x): 0.72, D(G(z)): 0.29\n",
            "Epoch [22/300], Step [400/468], d_loss: 1.5790, g_loss: 1.0944, D(x): 0.47, D(G(z)): 0.42\n",
            "Epoch [23/300], Step [200/468], d_loss: 1.8154, g_loss: 0.6326, D(x): 0.48, D(G(z)): 0.56\n",
            "Epoch [23/300], Step [400/468], d_loss: 1.2378, g_loss: 1.2316, D(x): 0.64, D(G(z)): 0.44\n",
            "Epoch [24/300], Step [200/468], d_loss: 1.3498, g_loss: 1.0936, D(x): 0.55, D(G(z)): 0.42\n",
            "Epoch [24/300], Step [400/468], d_loss: 1.7915, g_loss: 0.6285, D(x): 0.51, D(G(z)): 0.62\n",
            "Epoch [25/300], Step [200/468], d_loss: 2.1078, g_loss: 0.6015, D(x): 0.44, D(G(z)): 0.64\n",
            "Epoch [25/300], Step [400/468], d_loss: 1.7571, g_loss: 0.6782, D(x): 0.55, D(G(z)): 0.61\n",
            "Epoch [26/300], Step [200/468], d_loss: 1.5106, g_loss: 0.8319, D(x): 0.50, D(G(z)): 0.46\n",
            "Epoch [26/300], Step [400/468], d_loss: 1.3455, g_loss: 1.0784, D(x): 0.56, D(G(z)): 0.45\n",
            "Epoch [27/300], Step [200/468], d_loss: 1.1776, g_loss: 1.2662, D(x): 0.58, D(G(z)): 0.37\n",
            "Epoch [27/300], Step [400/468], d_loss: 0.9602, g_loss: 1.2944, D(x): 0.67, D(G(z)): 0.38\n",
            "Epoch [28/300], Step [200/468], d_loss: 0.8438, g_loss: 1.3261, D(x): 0.66, D(G(z)): 0.31\n",
            "Epoch [28/300], Step [400/468], d_loss: 1.3486, g_loss: 0.8731, D(x): 0.53, D(G(z)): 0.47\n",
            "Epoch [29/300], Step [200/468], d_loss: 1.0509, g_loss: 1.0466, D(x): 0.61, D(G(z)): 0.39\n",
            "Epoch [29/300], Step [400/468], d_loss: 1.7271, g_loss: 0.6420, D(x): 0.45, D(G(z)): 0.55\n",
            "Epoch [30/300], Step [200/468], d_loss: 1.7953, g_loss: 0.6183, D(x): 0.43, D(G(z)): 0.53\n",
            "Epoch [30/300], Step [400/468], d_loss: 1.2387, g_loss: 0.9233, D(x): 0.52, D(G(z)): 0.42\n",
            "Epoch [31/300], Step [200/468], d_loss: 1.3304, g_loss: 0.8208, D(x): 0.53, D(G(z)): 0.47\n",
            "Epoch [31/300], Step [400/468], d_loss: 1.4843, g_loss: 0.7315, D(x): 0.52, D(G(z)): 0.52\n",
            "Epoch [32/300], Step [200/468], d_loss: 1.4930, g_loss: 0.7936, D(x): 0.46, D(G(z)): 0.49\n",
            "Epoch [32/300], Step [400/468], d_loss: 1.2848, g_loss: 0.7852, D(x): 0.53, D(G(z)): 0.46\n",
            "Epoch [33/300], Step [200/468], d_loss: 1.6869, g_loss: 0.6862, D(x): 0.45, D(G(z)): 0.54\n",
            "Epoch [33/300], Step [400/468], d_loss: 1.2736, g_loss: 0.9204, D(x): 0.54, D(G(z)): 0.44\n",
            "Epoch [34/300], Step [200/468], d_loss: 1.8594, g_loss: 0.6251, D(x): 0.39, D(G(z)): 0.56\n",
            "Epoch [34/300], Step [400/468], d_loss: 1.1473, g_loss: 0.9064, D(x): 0.59, D(G(z)): 0.44\n",
            "Epoch [35/300], Step [200/468], d_loss: 0.9622, g_loss: 1.2973, D(x): 0.64, D(G(z)): 0.37\n",
            "Epoch [35/300], Step [400/468], d_loss: 1.6533, g_loss: 0.6731, D(x): 0.43, D(G(z)): 0.53\n",
            "Epoch [36/300], Step [200/468], d_loss: 1.3121, g_loss: 0.7783, D(x): 0.56, D(G(z)): 0.49\n",
            "Epoch [36/300], Step [400/468], d_loss: 1.3582, g_loss: 0.7968, D(x): 0.51, D(G(z)): 0.46\n",
            "Epoch [37/300], Step [200/468], d_loss: 1.5429, g_loss: 0.6490, D(x): 0.52, D(G(z)): 0.55\n",
            "Epoch [37/300], Step [400/468], d_loss: 1.0622, g_loss: 0.9539, D(x): 0.64, D(G(z)): 0.43\n",
            "Epoch [38/300], Step [200/468], d_loss: 1.3614, g_loss: 0.6720, D(x): 0.59, D(G(z)): 0.51\n",
            "Epoch [38/300], Step [400/468], d_loss: 0.7428, g_loss: 1.5097, D(x): 0.74, D(G(z)): 0.33\n",
            "Epoch [39/300], Step [200/468], d_loss: 0.8176, g_loss: 1.1684, D(x): 0.67, D(G(z)): 0.30\n",
            "Epoch [39/300], Step [400/468], d_loss: 1.3862, g_loss: 1.1535, D(x): 0.58, D(G(z)): 0.45\n",
            "Epoch [40/300], Step [200/468], d_loss: 1.8965, g_loss: 0.5648, D(x): 0.40, D(G(z)): 0.53\n",
            "Epoch [40/300], Step [400/468], d_loss: 1.0066, g_loss: 1.0854, D(x): 0.62, D(G(z)): 0.38\n",
            "Epoch [41/300], Step [200/468], d_loss: 1.0216, g_loss: 1.1051, D(x): 0.62, D(G(z)): 0.36\n",
            "Epoch [41/300], Step [400/468], d_loss: 1.6124, g_loss: 0.6969, D(x): 0.51, D(G(z)): 0.53\n",
            "Epoch [42/300], Step [200/468], d_loss: 1.8491, g_loss: 0.6736, D(x): 0.40, D(G(z)): 0.50\n",
            "Epoch [42/300], Step [400/468], d_loss: 1.2891, g_loss: 0.9033, D(x): 0.56, D(G(z)): 0.42\n",
            "Epoch [43/300], Step [200/468], d_loss: 0.9332, g_loss: 1.1003, D(x): 0.67, D(G(z)): 0.38\n",
            "Epoch [43/300], Step [400/468], d_loss: 1.1800, g_loss: 0.9212, D(x): 0.63, D(G(z)): 0.46\n",
            "Epoch [44/300], Step [200/468], d_loss: 1.0509, g_loss: 1.0428, D(x): 0.62, D(G(z)): 0.40\n",
            "Epoch [44/300], Step [400/468], d_loss: 1.3601, g_loss: 0.7851, D(x): 0.54, D(G(z)): 0.49\n",
            "Epoch [45/300], Step [200/468], d_loss: 1.4729, g_loss: 0.9506, D(x): 0.50, D(G(z)): 0.42\n",
            "Epoch [45/300], Step [400/468], d_loss: 0.9188, g_loss: 1.1628, D(x): 0.68, D(G(z)): 0.37\n",
            "Epoch [46/300], Step [200/468], d_loss: 1.7965, g_loss: 0.7926, D(x): 0.43, D(G(z)): 0.52\n",
            "Epoch [46/300], Step [400/468], d_loss: 0.9978, g_loss: 1.2105, D(x): 0.68, D(G(z)): 0.41\n",
            "Epoch [47/300], Step [200/468], d_loss: 1.0391, g_loss: 1.5320, D(x): 0.67, D(G(z)): 0.40\n",
            "Epoch [47/300], Step [400/468], d_loss: 1.4266, g_loss: 1.1205, D(x): 0.56, D(G(z)): 0.42\n",
            "Epoch [48/300], Step [200/468], d_loss: 0.7936, g_loss: 1.5749, D(x): 0.72, D(G(z)): 0.27\n",
            "Epoch [48/300], Step [400/468], d_loss: 0.9290, g_loss: 1.2251, D(x): 0.66, D(G(z)): 0.32\n",
            "Epoch [49/300], Step [200/468], d_loss: 1.5940, g_loss: 1.0187, D(x): 0.44, D(G(z)): 0.40\n",
            "Epoch [49/300], Step [400/468], d_loss: 1.2659, g_loss: 1.2783, D(x): 0.61, D(G(z)): 0.37\n",
            "Epoch [50/300], Step [200/468], d_loss: 1.1802, g_loss: 1.5950, D(x): 0.61, D(G(z)): 0.32\n",
            "Epoch [50/300], Step [400/468], d_loss: 1.0731, g_loss: 1.3645, D(x): 0.59, D(G(z)): 0.26\n",
            "Epoch [51/300], Step [200/468], d_loss: 0.9200, g_loss: 1.8651, D(x): 0.71, D(G(z)): 0.30\n",
            "Epoch [51/300], Step [400/468], d_loss: 0.5361, g_loss: 2.0519, D(x): 0.78, D(G(z)): 0.19\n",
            "Epoch [52/300], Step [200/468], d_loss: 0.7287, g_loss: 1.9269, D(x): 0.71, D(G(z)): 0.19\n",
            "Epoch [52/300], Step [400/468], d_loss: 1.0489, g_loss: 1.3071, D(x): 0.65, D(G(z)): 0.31\n",
            "Epoch [53/300], Step [200/468], d_loss: 0.8112, g_loss: 2.1117, D(x): 0.71, D(G(z)): 0.23\n",
            "Epoch [53/300], Step [400/468], d_loss: 0.5552, g_loss: 1.9205, D(x): 0.82, D(G(z)): 0.21\n",
            "Epoch [54/300], Step [200/468], d_loss: 0.9250, g_loss: 1.9042, D(x): 0.71, D(G(z)): 0.31\n",
            "Epoch [54/300], Step [400/468], d_loss: 0.9824, g_loss: 1.7802, D(x): 0.73, D(G(z)): 0.29\n",
            "Epoch [55/300], Step [200/468], d_loss: 0.7581, g_loss: 1.7519, D(x): 0.72, D(G(z)): 0.23\n",
            "Epoch [55/300], Step [400/468], d_loss: 0.5664, g_loss: 2.0290, D(x): 0.78, D(G(z)): 0.20\n",
            "Epoch [56/300], Step [200/468], d_loss: 0.8090, g_loss: 2.3082, D(x): 0.76, D(G(z)): 0.28\n",
            "Epoch [56/300], Step [400/468], d_loss: 0.3727, g_loss: 2.5345, D(x): 0.87, D(G(z)): 0.14\n",
            "Epoch [57/300], Step [200/468], d_loss: 0.4313, g_loss: 2.7366, D(x): 0.85, D(G(z)): 0.17\n",
            "Epoch [57/300], Step [400/468], d_loss: 0.6318, g_loss: 2.0445, D(x): 0.79, D(G(z)): 0.21\n",
            "Epoch [58/300], Step [200/468], d_loss: 0.7147, g_loss: 2.2451, D(x): 0.73, D(G(z)): 0.23\n",
            "Epoch [58/300], Step [400/468], d_loss: 0.7893, g_loss: 2.0323, D(x): 0.74, D(G(z)): 0.24\n",
            "Epoch [59/300], Step [200/468], d_loss: 0.5861, g_loss: 1.8723, D(x): 0.84, D(G(z)): 0.26\n",
            "Epoch [59/300], Step [400/468], d_loss: 0.7659, g_loss: 2.2246, D(x): 0.73, D(G(z)): 0.23\n",
            "Epoch [60/300], Step [200/468], d_loss: 1.1504, g_loss: 1.6902, D(x): 0.66, D(G(z)): 0.32\n",
            "Epoch [60/300], Step [400/468], d_loss: 1.0301, g_loss: 1.6336, D(x): 0.72, D(G(z)): 0.34\n",
            "Epoch [61/300], Step [200/468], d_loss: 1.0985, g_loss: 2.0042, D(x): 0.61, D(G(z)): 0.18\n",
            "Epoch [61/300], Step [400/468], d_loss: 1.1838, g_loss: 1.3560, D(x): 0.63, D(G(z)): 0.34\n",
            "Epoch [62/300], Step [200/468], d_loss: 0.9885, g_loss: 1.4075, D(x): 0.66, D(G(z)): 0.30\n",
            "Epoch [62/300], Step [400/468], d_loss: 0.7232, g_loss: 1.7895, D(x): 0.81, D(G(z)): 0.32\n",
            "Epoch [63/300], Step [200/468], d_loss: 1.0132, g_loss: 1.6105, D(x): 0.72, D(G(z)): 0.37\n",
            "Epoch [63/300], Step [400/468], d_loss: 0.8462, g_loss: 1.7342, D(x): 0.72, D(G(z)): 0.26\n",
            "Epoch [64/300], Step [200/468], d_loss: 0.7015, g_loss: 1.9736, D(x): 0.77, D(G(z)): 0.24\n",
            "Epoch [64/300], Step [400/468], d_loss: 0.8012, g_loss: 2.5854, D(x): 0.72, D(G(z)): 0.19\n",
            "Epoch [65/300], Step [200/468], d_loss: 1.0865, g_loss: 1.6749, D(x): 0.64, D(G(z)): 0.25\n",
            "Epoch [65/300], Step [400/468], d_loss: 0.9406, g_loss: 1.2918, D(x): 0.72, D(G(z)): 0.34\n",
            "Epoch [66/300], Step [200/468], d_loss: 0.5667, g_loss: 2.0734, D(x): 0.77, D(G(z)): 0.20\n",
            "Epoch [66/300], Step [400/468], d_loss: 0.9852, g_loss: 1.7181, D(x): 0.72, D(G(z)): 0.34\n",
            "Epoch [67/300], Step [200/468], d_loss: 0.8557, g_loss: 1.5844, D(x): 0.69, D(G(z)): 0.26\n",
            "Epoch [67/300], Step [400/468], d_loss: 0.6860, g_loss: 1.9235, D(x): 0.83, D(G(z)): 0.30\n",
            "Epoch [68/300], Step [200/468], d_loss: 0.7294, g_loss: 1.7510, D(x): 0.75, D(G(z)): 0.20\n",
            "Epoch [68/300], Step [400/468], d_loss: 0.5100, g_loss: 2.0836, D(x): 0.80, D(G(z)): 0.16\n",
            "Epoch [69/300], Step [200/468], d_loss: 0.6039, g_loss: 2.2797, D(x): 0.73, D(G(z)): 0.13\n",
            "Epoch [69/300], Step [400/468], d_loss: 0.8016, g_loss: 1.9926, D(x): 0.72, D(G(z)): 0.25\n",
            "Epoch [70/300], Step [200/468], d_loss: 0.5499, g_loss: 2.5287, D(x): 0.85, D(G(z)): 0.24\n",
            "Epoch [70/300], Step [400/468], d_loss: 0.3590, g_loss: 3.7258, D(x): 0.89, D(G(z)): 0.16\n",
            "Epoch [71/300], Step [200/468], d_loss: 0.5495, g_loss: 1.9651, D(x): 0.82, D(G(z)): 0.21\n",
            "Epoch [71/300], Step [400/468], d_loss: 0.4865, g_loss: 2.6803, D(x): 0.84, D(G(z)): 0.17\n",
            "Epoch [72/300], Step [200/468], d_loss: 0.4419, g_loss: 2.7775, D(x): 0.81, D(G(z)): 0.11\n",
            "Epoch [72/300], Step [400/468], d_loss: 0.4531, g_loss: 2.6732, D(x): 0.84, D(G(z)): 0.13\n",
            "Epoch [73/300], Step [200/468], d_loss: 0.5908, g_loss: 2.4868, D(x): 0.81, D(G(z)): 0.22\n",
            "Epoch [73/300], Step [400/468], d_loss: 0.6120, g_loss: 2.6252, D(x): 0.77, D(G(z)): 0.14\n",
            "Epoch [74/300], Step [200/468], d_loss: 0.8127, g_loss: 2.1556, D(x): 0.88, D(G(z)): 0.35\n",
            "Epoch [74/300], Step [400/468], d_loss: 0.7138, g_loss: 2.2890, D(x): 0.76, D(G(z)): 0.19\n",
            "Epoch [75/300], Step [200/468], d_loss: 0.7155, g_loss: 2.0277, D(x): 0.84, D(G(z)): 0.31\n",
            "Epoch [75/300], Step [400/468], d_loss: 0.7027, g_loss: 1.8508, D(x): 0.79, D(G(z)): 0.26\n",
            "Epoch [76/300], Step [200/468], d_loss: 0.9993, g_loss: 1.4876, D(x): 0.76, D(G(z)): 0.37\n",
            "Epoch [76/300], Step [400/468], d_loss: 0.7709, g_loss: 2.0414, D(x): 0.75, D(G(z)): 0.20\n",
            "Epoch [77/300], Step [200/468], d_loss: 0.8311, g_loss: 2.4845, D(x): 0.74, D(G(z)): 0.24\n",
            "Epoch [77/300], Step [400/468], d_loss: 0.9059, g_loss: 1.6076, D(x): 0.77, D(G(z)): 0.30\n",
            "Epoch [78/300], Step [200/468], d_loss: 0.7788, g_loss: 1.6516, D(x): 0.80, D(G(z)): 0.31\n",
            "Epoch [78/300], Step [400/468], d_loss: 0.5524, g_loss: 2.1196, D(x): 0.84, D(G(z)): 0.23\n",
            "Epoch [79/300], Step [200/468], d_loss: 0.4868, g_loss: 2.2296, D(x): 0.85, D(G(z)): 0.20\n",
            "Epoch [79/300], Step [400/468], d_loss: 1.0681, g_loss: 1.5331, D(x): 0.70, D(G(z)): 0.30\n",
            "Epoch [80/300], Step [200/468], d_loss: 0.7707, g_loss: 2.1106, D(x): 0.79, D(G(z)): 0.29\n",
            "Epoch [80/300], Step [400/468], d_loss: 1.0858, g_loss: 2.0895, D(x): 0.68, D(G(z)): 0.30\n",
            "Epoch [81/300], Step [200/468], d_loss: 0.5094, g_loss: 1.7907, D(x): 0.84, D(G(z)): 0.20\n",
            "Epoch [81/300], Step [400/468], d_loss: 0.4288, g_loss: 2.6686, D(x): 0.83, D(G(z)): 0.14\n",
            "Epoch [82/300], Step [200/468], d_loss: 0.3938, g_loss: 2.4793, D(x): 0.87, D(G(z)): 0.14\n",
            "Epoch [82/300], Step [400/468], d_loss: 0.5881, g_loss: 2.2225, D(x): 0.79, D(G(z)): 0.16\n",
            "Epoch [83/300], Step [200/468], d_loss: 0.4806, g_loss: 2.5154, D(x): 0.89, D(G(z)): 0.19\n",
            "Epoch [83/300], Step [400/468], d_loss: 0.7130, g_loss: 3.0468, D(x): 0.80, D(G(z)): 0.21\n",
            "Epoch [84/300], Step [200/468], d_loss: 0.4508, g_loss: 2.7148, D(x): 0.86, D(G(z)): 0.16\n",
            "Epoch [84/300], Step [400/468], d_loss: 0.7547, g_loss: 2.4659, D(x): 0.78, D(G(z)): 0.21\n",
            "Epoch [85/300], Step [200/468], d_loss: 0.5352, g_loss: 3.5377, D(x): 0.82, D(G(z)): 0.13\n",
            "Epoch [85/300], Step [400/468], d_loss: 0.4824, g_loss: 3.0867, D(x): 0.87, D(G(z)): 0.16\n",
            "Epoch [86/300], Step [200/468], d_loss: 0.4303, g_loss: 2.9484, D(x): 0.87, D(G(z)): 0.19\n",
            "Epoch [86/300], Step [400/468], d_loss: 0.9291, g_loss: 2.9991, D(x): 0.73, D(G(z)): 0.15\n",
            "Epoch [87/300], Step [200/468], d_loss: 0.4689, g_loss: 2.3979, D(x): 0.86, D(G(z)): 0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kAHSI03pkKH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}